{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39a30c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "import torch as tt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "path = \"./CIFAR-10\"\n",
    "train_dataset = datasets.CIFAR10(root=path, train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7aec2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return tt.maximum(x, tt.tensor(0.0, device=x.device))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = tt.exp(x - x.max(dim=1, keepdim=True).values)\n",
    "    return exp_x / exp_x.sum(dim=1, keepdim=True)\n",
    "\n",
    "def cross_entropy(pred, target):\n",
    "    N = target.size(0)\n",
    "    log_likelihood = -tt.log(pred[tt.arange(N), target] + 1e-9)\n",
    "    return log_likelihood.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08dec012",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = 3*32*32\n",
    "h1, h2, h3, h4 = 1024, 512, 256, 128\n",
    "D_out = 10\n",
    "\n",
    "class Net(tt.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = tt.nn.Linear(D_in, h1)\n",
    "        self.fc2 = tt.nn.Linear(h1, h2)\n",
    "        self.fc3 = tt.nn.Linear(h2, h3)\n",
    "        self.fc4 = tt.nn.Linear(h3, h4)\n",
    "        self.fc5 = tt.nn.Linear(h4, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)   # flatten\n",
    "        x = relu(self.fc1(x))\n",
    "        x = relu(self.fc2(x))\n",
    "        x = relu(self.fc3(x))\n",
    "        x = relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a1ac2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(model, lam):\n",
    "    l2 = 0.0\n",
    "    for p in model.parameters():\n",
    "        l2+= tt.sum(tt.abs(p)**2)\n",
    "    \n",
    "    return lam*l2\n",
    "\n",
    "def l1_loss(model, lam):\n",
    "    l1 = 0.0\n",
    "    for p in model.parameters():\n",
    "        l1+= tt.sum(tt.abs(p))\n",
    "    \n",
    "    return lam*l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a56a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running l2_loss with lambda=0.0001\n",
      "Batch 0, Loss: 2.3674\n",
      "Batch 100, Loss: 2.3578\n",
      "Batch 200, Loss: 2.0001\n",
      "Batch 300, Loss: 1.8889\n",
      "Batch 400, Loss: 1.9382\n",
      "Batch 500, Loss: 1.8697\n",
      "Batch 600, Loss: 1.8773\n",
      "Batch 700, Loss: 1.8942\n",
      "Batch 0, Loss: 1.9129\n",
      "Batch 100, Loss: 2.0236\n",
      "Batch 200, Loss: 1.7124\n",
      "Batch 300, Loss: 1.7897\n",
      "Batch 400, Loss: 1.7683\n",
      "Batch 500, Loss: 1.6548\n",
      "Batch 600, Loss: 1.7223\n",
      "Batch 700, Loss: 1.8107\n",
      "Test Loss: 1.6747, Test Acc: 40.26%\n",
      "\n",
      "Running l1_loss with lambda=0.0001\n",
      "Batch 0, Loss: 6.3640\n",
      "Batch 100, Loss: 3.7208\n",
      "Batch 200, Loss: 2.8255\n",
      "Batch 300, Loss: 2.5588\n",
      "Batch 400, Loss: 2.5221\n",
      "Batch 500, Loss: 2.4744\n",
      "Batch 600, Loss: 2.2785\n",
      "Batch 700, Loss: 2.3591\n",
      "Batch 0, Loss: 2.4403\n",
      "Batch 100, Loss: 2.2018\n",
      "Batch 200, Loss: 2.2636\n",
      "Batch 300, Loss: 2.2206\n",
      "Batch 400, Loss: 2.1848\n",
      "Batch 500, Loss: 2.3379\n",
      "Batch 600, Loss: 2.1920\n",
      "Batch 700, Loss: 2.2630\n",
      "Test Loss: 1.9828, Test Acc: 25.42%\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with tt.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            probs = model(imgs)\n",
    "            loss = cross_entropy(probs, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            preds = probs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "epoch = 2\n",
    "\n",
    "case = [(l2_loss, 1e-4), (l1_loss, 1e-4)]\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"./CIFAR-10\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for reguliser, lam in case:\n",
    "    print(f\"\\nRunning {reguliser.__name__} with lambda={lam}\")\n",
    "    model = Net().to(device)\n",
    "    opt = tt.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    for _ in range(epoch):\n",
    "        for i, (imgs, labels) in enumerate(train_loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            probs = model(imgs)\n",
    "            loss = cross_entropy(probs, labels) + reguliser(model, lam)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Batch {i}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    test_loss, test_acc = evaluate(model, test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Running l2_loss with lambda=0.0001\n",
    "Batch 0, Loss: 2.3674\n",
    "Batch 100, Loss: 2.3578\n",
    "Batch 200, Loss: 2.0001\n",
    "Batch 300, Loss: 1.8889\n",
    "Batch 400, Loss: 1.9382\n",
    "Batch 500, Loss: 1.8697\n",
    "Batch 600, Loss: 1.8773\n",
    "Batch 700, Loss: 1.8942\n",
    "Batch 0, Loss: 1.9129\n",
    "Batch 100, Loss: 2.0236\n",
    "Batch 200, Loss: 1.7124\n",
    "Batch 300, Loss: 1.7897\n",
    "Batch 400, Loss: 1.7683\n",
    "Batch 500, Loss: 1.6548\n",
    "Batch 600, Loss: 1.7223\n",
    "Batch 700, Loss: 1.8107\n",
    "Test Loss: 1.6747, Test Acc: 40.26%\n",
    "\n",
    "Running l1_loss with lambda=0.0001\n",
    "Batch 0, Loss: 6.3640\n",
    "Batch 100, Loss: 3.7208\n",
    "Batch 200, Loss: 2.8255\n",
    "Batch 300, Loss: 2.5588\n",
    "Batch 400, Loss: 2.5221\n",
    "Batch 500, Loss: 2.4744\n",
    "Batch 600, Loss: 2.2785\n",
    "Batch 700, Loss: 2.3591\n",
    "Batch 0, Loss: 2.4403\n",
    "Batch 100, Loss: 2.2018\n",
    "Batch 200, Loss: 2.2636\n",
    "Batch 300, Loss: 2.2206\n",
    "Batch 400, Loss: 2.1848\n",
    "Batch 500, Loss: 2.3379\n",
    "Batch 600, Loss: 2.1920\n",
    "Batch 700, Loss: 2.2630\n",
    "Test Loss: 1.9828, Test Acc: 25.42%'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6336c94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd05b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985a0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
